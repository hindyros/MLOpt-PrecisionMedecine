{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a32d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, CategoricalArrays, Plots, Statistics, Random, StatsPlots, Gurobi, JuMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e93453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4)"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>20×4 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Age</th><th style = \"text-align: left;\">DMRxAge</th><th style = \"text-align: left;\">BMI_mean</th><th style = \"text-align: left;\">HbA1c</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">67.7974</td><td style = \"text-align: right;\">9.30869</td><td style = \"text-align: right;\">40.4315</td><td style = \"text-align: right;\">7.2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">71.2909</td><td style = \"text-align: right;\">3.95346</td><td style = \"text-align: right;\">38.0979</td><td style = \"text-align: right;\">8.4</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">51.3101</td><td style = \"text-align: right;\">5.36619</td><td style = \"text-align: right;\">30.3333</td><td style = \"text-align: right;\">11.6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">64.4901</td><td style = \"text-align: right;\">0.821355</td><td style = \"text-align: right;\">48.5597</td><td style = \"text-align: right;\">8.1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">69.859</td><td style = \"text-align: right;\">8.95003</td><td style = \"text-align: right;\">42.3325</td><td style = \"text-align: right;\">12.6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">82.82</td><td style = \"text-align: right;\">1.05133</td><td style = \"text-align: right;\">32.305</td><td style = \"text-align: right;\">9.2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">51.5072</td><td style = \"text-align: right;\">7.78919</td><td style = \"text-align: right;\">26.8044</td><td style = \"text-align: right;\">7.7</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">37.9822</td><td style = \"text-align: right;\">2.73785</td><td style = \"text-align: right;\">31.0588</td><td style = \"text-align: right;\">10.7</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">38.4203</td><td style = \"text-align: right;\">1.67283</td><td style = \"text-align: right;\">27.7456</td><td style = \"text-align: right;\">9.6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">53.18</td><td style = \"text-align: right;\">3.24162</td><td style = \"text-align: right;\">31.1516</td><td style = \"text-align: right;\">7.5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">60.345</td><td style = \"text-align: right;\">6.71595</td><td style = \"text-align: right;\">32.2257</td><td style = \"text-align: right;\">8.9</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">53.2183</td><td style = \"text-align: right;\">5.82615</td><td style = \"text-align: right;\">33.701</td><td style = \"text-align: right;\">9.2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">46.3847</td><td style = \"text-align: right;\">5.86721</td><td style = \"text-align: right;\">32.9263</td><td style = \"text-align: right;\">9.5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: right;\">48.0657</td><td style = \"text-align: right;\">9.30869</td><td style = \"text-align: right;\">23.8571</td><td style = \"text-align: right;\">11.9</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">15</td><td style = \"text-align: right;\">82.3025</td><td style = \"text-align: right;\">7.66598</td><td style = \"text-align: right;\">28.7521</td><td style = \"text-align: right;\">9.7</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">16</td><td style = \"text-align: right;\">69.7577</td><td style = \"text-align: right;\">1.36619</td><td style = \"text-align: right;\">33.6318</td><td style = \"text-align: right;\">9.7</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">17</td><td style = \"text-align: right;\">63.2635</td><td style = \"text-align: right;\">4.89802</td><td style = \"text-align: right;\">37.9153</td><td style = \"text-align: right;\">6.5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">18</td><td style = \"text-align: right;\">43.2526</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">25.4362</td><td style = \"text-align: right;\">10.5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">19</td><td style = \"text-align: right;\">58.6913</td><td style = \"text-align: right;\">0.550308</td><td style = \"text-align: right;\">38.7224</td><td style = \"text-align: right;\">7.8</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">20</td><td style = \"text-align: right;\">67.5318</td><td style = \"text-align: right;\">1.64271</td><td style = \"text-align: right;\">35.5555</td><td style = \"text-align: right;\">7.8</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& Age & DMRxAge & BMI\\_mean & HbA1c\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 67.7974 & 9.30869 & 40.4315 & 7.2 \\\\\n",
       "\t2 & 71.2909 & 3.95346 & 38.0979 & 8.4 \\\\\n",
       "\t3 & 51.3101 & 5.36619 & 30.3333 & 11.6 \\\\\n",
       "\t4 & 64.4901 & 0.821355 & 48.5597 & 8.1 \\\\\n",
       "\t5 & 69.859 & 8.95003 & 42.3325 & 12.6 \\\\\n",
       "\t6 & 82.82 & 1.05133 & 32.305 & 9.2 \\\\\n",
       "\t7 & 51.5072 & 7.78919 & 26.8044 & 7.7 \\\\\n",
       "\t8 & 37.9822 & 2.73785 & 31.0588 & 10.7 \\\\\n",
       "\t9 & 38.4203 & 1.67283 & 27.7456 & 9.6 \\\\\n",
       "\t10 & 53.18 & 3.24162 & 31.1516 & 7.5 \\\\\n",
       "\t11 & 60.345 & 6.71595 & 32.2257 & 8.9 \\\\\n",
       "\t12 & 53.2183 & 5.82615 & 33.701 & 9.2 \\\\\n",
       "\t13 & 46.3847 & 5.86721 & 32.9263 & 9.5 \\\\\n",
       "\t14 & 48.0657 & 9.30869 & 23.8571 & 11.9 \\\\\n",
       "\t15 & 82.3025 & 7.66598 & 28.7521 & 9.7 \\\\\n",
       "\t16 & 69.7577 & 1.36619 & 33.6318 & 9.7 \\\\\n",
       "\t17 & 63.2635 & 4.89802 & 37.9153 & 6.5 \\\\\n",
       "\t18 & 43.2526 & 0.0 & 25.4362 & 10.5 \\\\\n",
       "\t19 & 58.6913 & 0.550308 & 38.7224 & 7.8 \\\\\n",
       "\t20 & 67.5318 & 1.64271 & 35.5555 & 7.8 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m20×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Age     \u001b[0m\u001b[1m DMRxAge  \u001b[0m\u001b[1m BMI_mean \u001b[0m\u001b[1m HbA1c   \u001b[0m\n",
       "     │\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "─────┼──────────────────────────────────────\n",
       "   1 │ 67.7974  9.30869    40.4315      7.2\n",
       "   2 │ 71.2909  3.95346    38.0979      8.4\n",
       "   3 │ 51.3101  5.36619    30.3333     11.6\n",
       "   4 │ 64.4901  0.821355   48.5597      8.1\n",
       "   5 │ 69.859   8.95003    42.3325     12.6\n",
       "   6 │ 82.82    1.05133    32.305       9.2\n",
       "   7 │ 51.5072  7.78919    26.8044      7.7\n",
       "   8 │ 37.9822  2.73785    31.0588     10.7\n",
       "   9 │ 38.4203  1.67283    27.7456      9.6\n",
       "  10 │ 53.18    3.24162    31.1516      7.5\n",
       "  11 │ 60.345   6.71595    32.2257      8.9\n",
       "  12 │ 53.2183  5.82615    33.701       9.2\n",
       "  13 │ 46.3847  5.86721    32.9263      9.5\n",
       "  14 │ 48.0657  9.30869    23.8571     11.9\n",
       "  15 │ 82.3025  7.66598    28.7521      9.7\n",
       "  16 │ 69.7577  1.36619    33.6318      9.7\n",
       "  17 │ 63.2635  4.89802    37.9153      6.5\n",
       "  18 │ 43.2526  0.0        25.4362     10.5\n",
       "  19 │ 58.6913  0.550308   38.7224      7.8\n",
       "  20 │ 67.5318  1.64271    35.5555      7.8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CSV.read(\"data_diabetes.csv\", DataFrame)\n",
    "print(size(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd963e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Float64}:\n",
       " -1.2167756723645808\n",
       " -0.48853088092443325\n",
       "  1.4534552295826264\n",
       " -0.6705920787844706\n",
       "  2.0603258891160827\n",
       " -0.003034353297668834\n",
       " -0.9133403425978528\n",
       "  0.9072716360025156\n",
       "  0.2397139105157139\n",
       " -1.034714474504544\n",
       " -0.18509555115770507\n",
       " -0.003034353297668834\n",
       "  0.17902684456236848\n",
       "  1.635516427442664\n",
       "  0.30040097646905933\n",
       "  0.30040097646905933\n",
       " -1.6415851340380003\n",
       "  0.7858975040958248\n",
       " -0.8526532766445073\n",
       " -0.8526532766445073"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing \n",
    "mu = mean(data.HbA1c)\n",
    "sigma = std(data.HbA1c)\n",
    "data.HbA1c = (data.HbA1c .- mu) ./ sigma\n",
    "\n",
    "# BMI is already normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf264c2",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "**Objective:** Split 20 numbers into two groups of 10 each to minimize discrepancies in centered first and second moments.\n",
    "\n",
    "**Methods to implement:**\n",
    "1. **Randomization:** Shuffle all numbers, split first half to group 1, rest to group 2\n",
    "2. **Re-randomization:** Do randomization 10,000 times, choose the one with lowest sum of absolute differences of first and second moments\n",
    "3. **Pair Matching:** Rank all numbers, for every consecutive pair, randomly split them into groups\n",
    "4. **Optimization:** Use MIO formulation from lecture notes with ρ = 0.5\n",
    "\n",
    "**Metrics to report:**\n",
    "- Total discrepancy: |μ_p(x) - μ_q(x)| + |σ²_p(x) - σ²_q(x)|\n",
    "- Mean difference: |μ_p(x) - μ_q(x)|\n",
    "- Variance difference: |σ²_p(x) - σ²_q(x)|\n",
    "\n",
    "**Random seed:** 15095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13642db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. Randomization ===\n",
      "Mean difference: 0.34591627593407004\n",
      "Variance difference: 0.268595353705696\n",
      "Total discrepancy: 0.614511629639766\n",
      "\n",
      "=== 2. Re-randomization (best of 10000) ===\n",
      "Mean difference: 0.006068706595334564\n",
      "Variance difference: 0.001068046792466859\n",
      "Total discrepancy: 0.007136753387801423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save original data for re-randomization\n",
    "data_original = copy(data)\n",
    "n = nrow(data)\n",
    "n_half = div(n, 2)\n",
    "seed = 15095\n",
    "\n",
    "# 1. Randomization: Shuffle all the n samples.\n",
    "# Split the resulting data into two groups of size n/2.\n",
    "Random.seed!(seed)\n",
    "data_shuffled = data_original[shuffle(1:nrow(data_original)), :]\n",
    "group_1_rand = data_shuffled[1:n_half, :]\n",
    "group_2_rand = data_shuffled[n_half+1:end, :]\n",
    "\n",
    "# Calculate discrepancies for randomization\n",
    "# Use population variance (divide by n) for consistency with optimization formulation\n",
    "mu_1_rand = mean(group_1_rand.HbA1c)\n",
    "mu_2_rand = mean(group_2_rand.HbA1c)\n",
    "var_1_rand = var(group_1_rand.HbA1c, corrected=false)\n",
    "var_2_rand = var(group_2_rand.HbA1c, corrected=false)\n",
    "diff_mean_rand = abs(mu_1_rand - mu_2_rand)\n",
    "diff_var_rand = abs(var_1_rand - var_2_rand)\n",
    "total_diff_rand = diff_mean_rand + diff_var_rand\n",
    "\n",
    "println(\"=== 1. Randomization ===\")\n",
    "println(\"Mean difference: \", diff_mean_rand)\n",
    "println(\"Variance difference: \", diff_var_rand)\n",
    "println(\"Total discrepancy: \", total_diff_rand)\n",
    "println()\n",
    "\n",
    "# 2. Re-randomization: Do randomization 10000 times and choose the one with the lowest sum\n",
    "min_diff = Inf\n",
    "best_group_1 = nothing\n",
    "best_group_2 = nothing\n",
    "\n",
    "for i in 1:10000\n",
    "    Random.seed!(seed + i)\n",
    "    data_shuffled = data_original[shuffle(1:nrow(data_original)), :]\n",
    "    group_1 = data_shuffled[1:n_half, :]\n",
    "    group_2 = data_shuffled[n_half+1:end, :]\n",
    "    \n",
    "    mu_1 = mean(group_1.HbA1c)\n",
    "    mu_2 = mean(group_2.HbA1c)\n",
    "    # Use population variance (divide by n) for consistency\n",
    "    var_1 = var(group_1.HbA1c, corrected=false)\n",
    "    var_2 = var(group_2.HbA1c, corrected=false)\n",
    "    \n",
    "    diff_mean = abs(mu_1 - mu_2)\n",
    "    diff_var = abs(var_1 - var_2)\n",
    "    diff = diff_mean + diff_var\n",
    "    \n",
    "    if diff < min_diff\n",
    "        min_diff = diff\n",
    "        best_group_1 = copy(group_1)\n",
    "        best_group_2 = copy(group_2)\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"=== 2. Re-randomization (best of 10000) ===\")\n",
    "mu_1_rerand = mean(best_group_1.HbA1c)\n",
    "mu_2_rerand = mean(best_group_2.HbA1c)\n",
    "# Use population variance (divide by n) for consistency\n",
    "var_1_rerand = var(best_group_1.HbA1c, corrected=false)\n",
    "var_2_rerand = var(best_group_2.HbA1c, corrected=false)\n",
    "diff_mean_rerand = abs(mu_1_rerand - mu_2_rerand)\n",
    "diff_var_rerand = abs(var_1_rerand - var_2_rerand)\n",
    "println(\"Mean difference: \", diff_mean_rerand)\n",
    "println(\"Variance difference: \", diff_var_rerand)\n",
    "println(\"Total discrepancy: \", min_diff)\n",
    "println()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9977e927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 3. Pair Matching ===\n",
      "Mean difference: 0.07889318573934927\n",
      "Variance difference: 0.06397231994882646\n",
      "Total discrepancy: 0.14286550568817574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Pair Matching: Rank all numbers. For every continuous two numbers, randomly split them\n",
    "# \n",
    "# WHY PAIR MATCHING?\n",
    "# Pair matching is a common technique in experimental design and causal inference:\n",
    "# 1. By pairing similar observations (consecutive ranked values), we reduce variance within pairs\n",
    "# 2. Random assignment within pairs maintains randomization (important for causal inference)\n",
    "# 3. This heuristic often achieves better balance than pure randomization while still being random\n",
    "# 4. It's computationally simple compared to optimization but often performs well\n",
    "# \n",
    "# The idea: If two observations are similar (consecutive in rank), splitting them randomly\n",
    "# ensures one goes to each group, maintaining balance while preserving randomness.\n",
    "Random.seed!(seed)\n",
    "data_sorted = sort(data_original, :HbA1c)\n",
    "group_1_indices = Int[]\n",
    "group_2_indices = Int[]\n",
    "\n",
    "for i in 1:2:n-1\n",
    "    # For each pair of consecutive numbers, randomly assign to groups\n",
    "    if rand() < 0.5\n",
    "        push!(group_1_indices, i)\n",
    "        push!(group_2_indices, i+1)\n",
    "    else\n",
    "        push!(group_1_indices, i+1)\n",
    "        push!(group_2_indices, i)\n",
    "    end\n",
    "end\n",
    "\n",
    "# If n is odd, assign the last one randomly\n",
    "if n % 2 == 1\n",
    "    if rand() < 0.5\n",
    "        push!(group_1_indices, n)\n",
    "    else\n",
    "        push!(group_2_indices, n)\n",
    "    end\n",
    "end\n",
    "\n",
    "group_1_pair = data_sorted[group_1_indices, :]\n",
    "group_2_pair = data_sorted[group_2_indices, :]\n",
    "\n",
    "# Calculate discrepancies for Pair Matching\n",
    "mu_1_pair = mean(group_1_pair.HbA1c)\n",
    "mu_2_pair = mean(group_2_pair.HbA1c)\n",
    "# Use population variance (divide by n) for consistency with optimization formulation\n",
    "var_1_pair = var(group_1_pair.HbA1c, corrected=false)\n",
    "var_2_pair = var(group_2_pair.HbA1c, corrected=false)\n",
    "diff_mean_pair = abs(mu_1_pair - mu_2_pair)\n",
    "diff_var_pair = abs(var_1_pair - var_2_pair)\n",
    "total_diff_pair = diff_mean_pair + diff_var_pair\n",
    "\n",
    "println(\"=== 3. Pair Matching ===\")\n",
    "println(\"Mean difference: \", diff_mean_pair)\n",
    "println(\"Variance difference: \", diff_var_pair)\n",
    "println(\"Total discrepancy: \", total_diff_pair)\n",
    "println()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74789c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-08-20\n",
      "=== 4. Optimization (MIP) ===\n",
      "Mean difference: 0.006068706595331991\n",
      "Variance difference: 0.0004051211971438651\n",
      "Total discrepancy: 0.006473827792475856\n",
      "\n",
      "=== Final Summary ===\n",
      "Randomization total discrepancy: 0.614511629639766\n",
      "Re-randomization total discrepancy: 0.007136753387801423\n",
      "Pair Matching total discrepancy: 0.14286550568817574\n",
      "Optimization total discrepancy: 0.006473827792475856\n"
     ]
    }
   ],
   "source": [
    "# Optimization: Use the formulation in lecture notes. Solve this mixed integer optimization problem. Please set ρ = 0.5.\n",
    "model = Model(Gurobi.Optimizer)\n",
    "set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "\n",
    "m = 2  # number of groups\n",
    "k = n_half  # size of each group (n/2)\n",
    "rho = 0.5\n",
    "\n",
    "# Get the HbA1c values\n",
    "y = data_original.HbA1c\n",
    "\n",
    "# Variables\n",
    "# x[i,p] = 1 if item i is assigned to group p, 0 otherwise\n",
    "@variable(model, x[i in 1:n, p in 1:m], Bin)\n",
    "# d is the maximum discrepancy\n",
    "@variable(model, d >= 0)\n",
    "# Auxiliary variables for means: μ_p = (1/k) * Σ_i x[i,p] * y[i]\n",
    "@variable(model, mu[p in 1:m])\n",
    "# Auxiliary variables for sum of squares: sum_sq_p = Σ_i x[i,p] * y[i]^2\n",
    "@variable(model, sum_sq[p in 1:m] >= 0)\n",
    "# Auxiliary variables for variances: σ_p^2 = (1/k) * sum_sq_p - μ_p^2\n",
    "@variable(model, var_p[p in 1:m])\n",
    "\n",
    "# Objective: minimize the maximum discrepancy\n",
    "@objective(model, Min, d)\n",
    "\n",
    "# Constraints for means: μ_p = (1/k) * Σ_i x[i,p] * y[i]\n",
    "for p in 1:m\n",
    "    @constraint(model, mu[p] == (1/k) * sum(x[i,p] * y[i] for i in 1:n))\n",
    "end\n",
    "\n",
    "# Constraints for sum of squares: sum_sq_p = Σ_i x[i,p] * y[i]^2\n",
    "for p in 1:m\n",
    "    @constraint(model, sum_sq[p] == sum(x[i,p] * y[i]^2 for i in 1:n))\n",
    "end\n",
    "\n",
    "# Constraints for variances: σ_p^2 = (1/k) * sum_sq_p - μ_p^2\n",
    "# Note: This is quadratic. Gurobi can handle MIQP.\n",
    "for p in 1:m\n",
    "    @constraint(model, var_p[p] == (1/k) * sum_sq[p] - mu[p]^2)\n",
    "end\n",
    "\n",
    "# Assignment constraints: each item assigned to exactly one group\n",
    "for i in 1:n\n",
    "    @constraint(model, sum(x[i,p] for p in 1:m) == 1)\n",
    "end\n",
    "\n",
    "# Group size constraints: each group has exactly k items\n",
    "for p in 1:m\n",
    "    @constraint(model, sum(x[i,p] for i in 1:n) == k)\n",
    "end\n",
    "\n",
    "# Discrepancy constraints for all pairs p < q\n",
    "# We need to cover all combinations of absolute values:\n",
    "# d ≥ μ_p - μ_q + ρ(σ_p^2 - σ_q^2)\n",
    "# d ≥ μ_p - μ_q + ρ(σ_q^2 - σ_p^2)\n",
    "# d ≥ μ_q - μ_p + ρ(σ_p^2 - σ_q^2)\n",
    "# d ≥ μ_q - μ_p + ρ(σ_q^2 - σ_p^2)\n",
    "for p in 1:m-1\n",
    "    for q in (p+1):m\n",
    "        @constraint(model, d >= mu[p] - mu[q] + rho * (var_p[p] - var_p[q]))\n",
    "        @constraint(model, d >= mu[p] - mu[q] + rho * (var_p[q] - var_p[p]))\n",
    "        @constraint(model, d >= mu[q] - mu[p] + rho * (var_p[p] - var_p[q]))\n",
    "        @constraint(model, d >= mu[q] - mu[p] + rho * (var_p[q] - var_p[p]))\n",
    "    end\n",
    "end\n",
    "\n",
    "# Solve the model\n",
    "optimize!(model)\n",
    "\n",
    "# Results\n",
    "x_opt = value.(x)\n",
    "d_opt = value(d)\n",
    "mu_opt = [value(mu[p]) for p in 1:m]\n",
    "var_opt = [value(var_p[p]) for p in 1:m]\n",
    "\n",
    "# Determine group assignments\n",
    "group_1_opt_indices = [i for i in 1:n if x_opt[i,1] > 0.5]\n",
    "group_2_opt_indices = [i for i in 1:n if x_opt[i,2] > 0.5]\n",
    "\n",
    "group_1_opt = data_original[group_1_opt_indices, :]\n",
    "group_2_opt = data_original[group_2_opt_indices, :]\n",
    "\n",
    "# Calculate discrepancy for reporting (unweighted for comparison with other methods)\n",
    "opt_mean_diff = abs(mu_opt[1] - mu_opt[2])\n",
    "opt_var_diff = abs(var_opt[1] - var_opt[2])\n",
    "opt_total_diff = opt_mean_diff + opt_var_diff\n",
    "\n",
    "println(\"=== 4. Optimization (MIP) ===\")\n",
    "println(\"Mean difference: \", opt_mean_diff)\n",
    "println(\"Variance difference: \", opt_var_diff)\n",
    "println(\"Total discrepancy: \", opt_total_diff)\n",
    "println()\n",
    "\n",
    "println(\"=== Final Summary ===\")\n",
    "println(\"Randomization total discrepancy: \", total_diff_rand)\n",
    "println(\"Re-randomization total discrepancy: \", min_diff)\n",
    "println(\"Pair Matching total discrepancy: \", total_diff_pair)\n",
    "println(\"Optimization total discrepancy: \", opt_total_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4494ce",
   "metadata": {},
   "source": [
    "### (b)\n",
    "\n",
    "**Note:** This is a DIFFERENT problem from part (a). Part (a) compared four methods using mean/variance discrepancy. Part (b) is a separate optimisation problem with a different objective function.\n",
    "\n",
    "**Objective:** Minimise the sum of pairwise absolute differences between numbers in group 1 and group 2.\n",
    "\n",
    "We want to solve\n",
    "\n",
    "$$\n",
    "\\min \\sum_{i \\in \\text{group 1}} \\sum_{j \\in \\text{group 2}}\n",
    "  \\lvert w'_i - w'_j \\rvert,\n",
    "$$\n",
    "\n",
    "where \\(w'_i\\) are the (standardised) HbA1c values. The \\(w'_i\\) are data; the only decision is how to split the subjects into two groups of equal size.\n",
    "\n",
    "---\n",
    "\n",
    "#### Modelling as a MILP\n",
    "\n",
    "We introduce binary variables\n",
    "\n",
    "$$\n",
    "z_i =\n",
    "\\begin{cases}\n",
    "1 & \\text{if subject } i \\text{ is in group 1},\\\\[4pt]\n",
    "0 & \\text{if subject } i \\text{ is in group 2},\n",
    "\\end{cases}\n",
    "\\qquad i = 1,\\dots,n.\n",
    "$$\n",
    "\n",
    "The group–size constraint is\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n z_i = \\frac{n}{2}.\n",
    "$$\n",
    "\n",
    "For each unordered pair \\((i,j)\\) with \\(i<j\\), we precompute the constant\n",
    "\n",
    "$$\n",
    "c_{ij} = \\lvert w'_i - w'_j \\rvert.\n",
    "$$\n",
    "\n",
    "We then introduce binary variables \\(d_{ij}\\) for \\(1 \\le i < j \\le n\\) with the intended meaning:\n",
    "\n",
    "- \\(d_{ij} = 1\\) if subjects \\(i\\) and \\(j\\) are in **different** groups (that is, \\(z_i \\ne z_j\\)),\n",
    "- \\(d_{ij} = 0\\) if they are in the **same** group.\n",
    "\n",
    "The logical relation \\(d_{ij} = \\lvert z_i - z_j \\rvert\\) is enforced with the following linear constraints, for all \\(1 \\le i < j \\le n\\):\n",
    "\n",
    "$$\n",
    "d_{ij} \\ge z_i - z_j,\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_{ij} \\ge z_j - z_i,\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_{ij} \\le z_i + z_j,\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_{ij} \\le 2 - (z_i + z_j).\n",
    "$$\n",
    "\n",
    "Finally, the objective (5.1) becomes\n",
    "\n",
    "$$\n",
    "\\min \\sum_{1 \\le i < j \\le n} c_{ij}\\, d_{ij},\n",
    "$$\n",
    "\n",
    "because \\(d_{ij} = 1\\) exactly when \\(i\\) and \\(j\\) are split across the two groups, and then we pay the cost \\(c_{ij} = \\lvert w'_i - w'_j \\rvert\\).\n",
    "\n",
    "Solving this MILP gives the partition of subjects that minimises the sum of cross-group absolute differences in HbA1c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3677831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-08-20\n",
      "=== Part (b): Minimize Pairwise Differences (MILP) ===\n",
      "Optimal objective value: 111.17870482652917\n",
      "Group 1 size: 10\n",
      "Group 2 size: 10\n",
      "\n",
      "=== Comparison ===\n",
      "Randomization approach (from part a.1) objective: 115.79092183898342\n",
      "Optimization approach (MILP) objective: 111.17870482652917\n",
      "Improvement: 4.612217012454252 (3.98% reduction)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part (b): Minimize sum of pairwise absolute differences\n",
    "# Objective: min Σ_{i in group1, j in group2} |w'_i - w'_j|\n",
    "\n",
    "model_pair = Model(Gurobi.Optimizer)\n",
    "set_optimizer_attribute(model_pair, \"OutputFlag\", 0)\n",
    "\n",
    "# Get the HbA1c values (w'_i) as a plain vector\n",
    "w = data_original.HbA1c\n",
    "n = length(w)\n",
    "n_half = Int(n ÷ 2)\n",
    "\n",
    "# Precompute pairwise absolute differences c[i,j] = |w[i] - w[j]| for i < j\n",
    "c = Dict{Tuple{Int,Int},Float64}()\n",
    "for i in 1:n\n",
    "    for j in i+1:n\n",
    "        c[(i,j)] = abs(w[i] - w[j])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Binary variables: z[i] = 1 if item i is in group 1, 0 if in group 2\n",
    "@variable(model_pair, z[1:n], Bin)\n",
    "\n",
    "# Binary variables: d[i,j] = 1 if i and j are in different groups, 0 otherwise\n",
    "# Only need them for i < j\n",
    "@variable(model_pair, d[i in 1:n, j in i+1:n], Bin)\n",
    "\n",
    "# Objective: sum of pairwise costs over pairs that are split across groups\n",
    "@objective(model_pair, Min,\n",
    "    sum(c[(i,j)] * d[i,j] for i in 1:n for j in i+1:n)\n",
    ")\n",
    "\n",
    "# Group size constraint: each group has exactly n_half items\n",
    "@constraint(model_pair, sum(z[i] for i in 1:n) == n_half)\n",
    "\n",
    "# \"Different groups\" constraints: d[i,j] = |z[i] - z[j]|\n",
    "for i in 1:n\n",
    "    for j in i+1:n\n",
    "        @constraint(model_pair, d[i,j] >= z[i] - z[j])\n",
    "        @constraint(model_pair, d[i,j] >= z[j] - z[i])\n",
    "        @constraint(model_pair, d[i,j] <= z[i] + z[j])\n",
    "        @constraint(model_pair, d[i,j] <= 2 - (z[i] + z[j]))\n",
    "    end\n",
    "end\n",
    "\n",
    "# Solve the model\n",
    "optimize!(model_pair)\n",
    "\n",
    "# Extract results\n",
    "z_pair_opt = value.(z)\n",
    "obj_pair_opt = objective_value(model_pair)\n",
    "\n",
    "# Determine group assignments\n",
    "group_1_pair_indices = [i for i in 1:n if z_pair_opt[i] > 0.5]\n",
    "group_2_pair_indices = [i for i in 1:n if z_pair_opt[i] < 0.5]\n",
    "\n",
    "group_1_pair_opt = data_original[group_1_pair_indices, :]\n",
    "group_2_pair_opt = data_original[group_2_pair_indices, :]\n",
    "\n",
    "println(\"=== Part (b): Minimize Pairwise Differences (MILP) ===\")\n",
    "println(\"Optimal objective value: \", obj_pair_opt)\n",
    "println(\"Group 1 size: \", length(group_1_pair_indices))\n",
    "println(\"Group 2 size: \", length(group_2_pair_indices))\n",
    "println()\n",
    "\n",
    "# Calculate objective for randomization approach from part (a)\n",
    "rand_obj = 0.0\n",
    "for i in 1:n_half\n",
    "    for j in 1:n_half\n",
    "        rand_obj += abs(group_1_rand.HbA1c[i] - group_2_rand.HbA1c[j])\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"=== Comparison ===\")\n",
    "println(\"Randomization approach (from part a.1) objective: \", rand_obj)\n",
    "println(\"Optimization approach (MILP) objective: \", obj_pair_opt)\n",
    "println(\"Improvement: \", rand_obj - obj_pair_opt, \" (\",\n",
    "        round(100 * (rand_obj - obj_pair_opt) / rand_obj, digits=2),\n",
    "        \"% reduction)\")\n",
    "println()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cf4fb7",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "The optimization approach (MILP) finds the optimal assignment that minimizes the sum of pairwise absolute differences between groups. Compared to the randomization approach from part (a.1), the MILP solution achieves a lower objective value, demonstrating that optimization can systematically find better solutions than random assignment. This has been demonstrated to be true in both scenario explored (single sample assignment to 2 groups and pairwise assignment to two groups).\n",
    "\n",
    "The improvement shows that using optimization, we can achieve better balance between the groups in terms of pairwise differences. This is particularly valuable when we want to minimize discrepancies between groups for statistical analysis or experimental design purposes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
