{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82bcff1a-370f-484e-944b-ff3e70420ac5",
   "metadata": {},
   "source": [
    "# Homework 5, Question 3 (40 points)\n",
    "In this question, we explore the R.O.A.D. methodology. We will consider `spleen_mlopt_final_train.csv` and `spleen_mlopt_final_test.csv`, a subset of data on splenectomy that consists of 2,400 individuals. The features, treatment, and outcome variables are as follows:\n",
    "- Features: `sex`, `age`, `sbp`, `pulserate`, `respiratoryrate`, `pulseoximetry`, `totalgcs`, `intubated`, `bmi`, etc.\n",
    "- Treatment: `treatment`, which could either be \"splenectomy\" (spleen removal surgery, e.g. treatment) or \"observation\" (control - e.g. no surgery)\n",
    "- Outcome: `o_mortality`, where 1 indicates patient death (\"expiration\") and 0 otherwise\n",
    "\n",
    "*__Important:__* Please note to use the seed provided in all places (data splitting and any tree training), and do not change anything regarding the order/columns in the `spleen.csv` dataset, unless otherwise specified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0631f9-dbc8-44fe-b46c-b217d3531f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "# If you need to install packages, please do not leave the output of installation in your homework submission.\n",
    "using CSV, DataFrames, CategoricalArrays, Plots, Statistics, Random, StatsPlots, Gurobi, JuMP\n",
    "\n",
    "seed = 42;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a16fe3-8ee3-4f03-a781-2df232f6114a",
   "metadata": {},
   "source": [
    "#### Read in the data and get the features, treatment, and outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ec001-d9f5-442c-a91a-1f696bcddc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CSV.read(\"spleen_mlopt_final_train.csv\", DataFrame)\n",
    "test = CSV.read(\"spleen_mlopt_final_test.csv\", DataFrame)\n",
    "\n",
    "X_train = train[:, Not([:treatment, :o_mortality])]\n",
    "t_train = train[:, :treatment]\n",
    "y_train = train[:, :o_mortality]\n",
    "\n",
    "X_test = test[:, Not([:treatment, :o_mortality])]\n",
    "t_test = test[:, :treatment]\n",
    "y_test = test[:, :o_mortality];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771bbd5a-ef15-407e-9977-9ea390bf1d97",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "In this part, we will perform the first main step of R.O.A.D., which removes observed confounding by selecting a matched dataset from the original set of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b47dab7-34da-40df-bea3-e339b70136c2",
   "metadata": {},
   "source": [
    "### Part 1(a) - 5 points\n",
    "\n",
    "Using the *__control patients in the training dataset__*, train a `RandomForest` via `GridSearch` to predict mortality outcome; use cross-validation with 5 folds and criterion of AUC to finetune the hyperparameters amongst the following possible values: `max_depth` of [5], `minbucket` of [20, 50], and `num_trees` of [50, 100]. This model is trained to estimate mortality outcomes if patients did not receive treatment. \n",
    "\n",
    "Please answer the following questions.\n",
    "- How good is our estimator? That is, what is the AUC and accuracy of our estimator on the control patients in the test set?\n",
    "- Use this model to predict what the the mortality risk (e.g. the probability of mortality) would be if all the training set patients did not receive treatment. What is the mortality risk for the last training set patient (patient \\#1920)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b441c-966a-42a0-ac64-01008628c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train_control = findall(val -> val == \"observation\", t_train)\n",
    "X_train_control = X_train[idx_train_control, :]\n",
    "t_train_control = t_train[idx_train_control]\n",
    "y_train_control = y_train[idx_train_control]\n",
    "\n",
    "idx_test_control = findall(val -> val == \"observation\", t_test)\n",
    "X_test_control = X_train[idx_test_control, :]\n",
    "t_test_control = t_train[idx_test_control]\n",
    "y_test_control = y_train[idx_test_control];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a60b2-7082-4c11-92a5-9e3cd965f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RF on control training data\n",
    "depths = [5]\n",
    "minbuckets = [20, 50]\n",
    "num_trees = [50, 100]\n",
    "\n",
    "# TODO\n",
    "# grid_rf = [TODO]\n",
    "# IAI.fit_cv!([TODO])\n",
    "\n",
    "# Get best model\n",
    "lnr = IAI.get_learner(grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66efb4b-a0d2-4465-84c3-58b5794da8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC, accuracy for test set \n",
    "# println(\"Test AUC score: \", round([TODO], digits=4))\n",
    "# println(\"Test Accuracy: \", round([TODO], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b856de-7cdf-43ae-9d97-7814bef19b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Mortality risk of last training patient: \", [TODO])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc9822-9af8-40cb-a398-f10fb5d7c587",
   "metadata": {},
   "source": [
    "### Part 1(b) - 2.5 points\n",
    "\n",
    "We now divide the training test patients into 5 equally-sized buckets, in order of increasing predicted mortality risk. How many patients received treatment in Bucket 5? You should fill in the TODO section to print this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b9061f-aa81-4cbc-bfc9-be32e67a1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and bucket\n",
    "y_proba = IAI.predict_proba(lnr, X_train)[:, 2]\n",
    "train[!, \"y_proba\"] = y_proba\n",
    "train = sort!(train, :y_proba);\n",
    "\n",
    "groups = []\n",
    "num_groups = 5\n",
    "num_per_group = Integer(ceil(size(train)[1] / num_groups))\n",
    "\n",
    "for idx in 1:num_groups\n",
    "    start_idx = (idx-1)*num_per_group+1\n",
    "    if idx==num_groups\n",
    "        end_idx = size(train)[1]\n",
    "    else\n",
    "        end_idx = idx*num_per_group\n",
    "    end\n",
    "    println(start_idx)\n",
    "    println(end_idx)\n",
    "    subdf = train[start_idx:end_idx, :]\n",
    "    push!(groups, subdf)\n",
    "    frequencies = sort!(combine(groupby(subdf, :treatment), nrow => :frequency), :treatment)\n",
    "\n",
    "    # [TODO]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4702e810-42e5-4ad0-992e-e9dee54b7fb0",
   "metadata": {},
   "source": [
    "### Part 1(c) - 2.5 points\n",
    "\n",
    "For each bucket $k\\in 1,...,5$, we compute a corresponding distance matrix $\\textbf{D}_k$, such that $\\textbf{D}_k[i,j]$ is the squared Euclidean norm between the $i$-th treatment group individual and the $j$-th control group individual. The distance should be computed on three features: [`sex`, `age`, `bmi`]. Make sure to normalize the non-binary features before computing the distance, by subtracting the full training mean and dividing by the full training range, such that they fall between 0 and 1. Formally, let $x_{i,s}$ be the value of the feature $s$ for individual $i$; then the normalized value $\\hat{x}_{i,s}$ is defined:\n",
    "        $$\\hat{x}_{i,s} = \\frac{x - \\min_{j\\in\\mathcal{T}}(x)}{\\max_{j\\in\\mathcal{T}}(x) - \\min_{j\\in\\mathcal{T}}(x)}, \\quad \\forall i\\in\\mathcal{T}, \\forall s,$$\n",
    " where $\\mathcal{T}$ is the set of training datapoints.\n",
    "        \n",
    "What is the dimension of $\\mathbf{D}_{5}$ and what is the distance between treatment individual 10 and control individual 12 in the 5th bucket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d8ea1-7f8f-4e46-add1-1ea98192b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_dist(row1, row2, features)\n",
    "    dist = 0\n",
    "    for f in features\n",
    "        dist += (row1[f] - row2[f])^2\n",
    "    end\n",
    "    return dist\n",
    "end\n",
    "\n",
    "function compute_dist_matrix(df_treatment1, df_treatment2, features)\n",
    "    n1 = size(df_treatment1)[1]\n",
    "    n2 = size(df_treatment2)[1]\n",
    "    distances = zeros(n1, n2)\n",
    "    for i in 1:n1\n",
    "        for j in 1:n2\n",
    "            distances[i,j] = compute_dist(df_treatment1[i, :], df_treatment2[j, :], features)\n",
    "        end\n",
    "    end\n",
    "    return distances\n",
    "end\n",
    "\n",
    "min_age = minimum(train[:, \"age\"])\n",
    "max_age = maximum(train[:, \"age\"])\n",
    "min_bmi = minimum(train[:, \"bmi\"])\n",
    "max_bmi = maximum(train[:, \"bmi\"])\n",
    "\n",
    "matching_features = [\"sex\", \"age\", \"bmi\"]\n",
    "group_dist = []\n",
    "std_gs = []\n",
    "for g in groups\n",
    "    std_g = copy(g)[:, vcat(matching_features, [\"treatment\"])]\n",
    "    # [TODO: normalize non-binary features - you may use the min/max values computed above]\n",
    "    # [TODO: call the compute_dist_matrix function with the appropriate arguments to compute the distance matrix for each group]\n",
    "    # dist_matrix = ...\n",
    "    \n",
    "    push!(group_dist, dist_matrix)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a69e8f-8f01-4a49-8c66-3cfd51f4bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# println(\"Shape of bucket 5: \", [TODO])\n",
    "# println(\"Distance b/w treatment 10 and control 12 in bucket 5: \", [TODO])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea79a85-6969-4f46-b5f8-fed605140797",
   "metadata": {},
   "source": [
    "### Part 1(d) - 7 points\n",
    "\n",
    "For each bucket $k\\in 1,...,5$, implement and run the matching algorithm from lecture:\n",
    "        $$\\begin{aligned}\n",
    "            \\min_{\\boldsymbol{z}} & \\quad \\sum_{i\\in\\mathcal{S}_1^k}\\sum_{j\\in\\mathcal{S}_0^k} z_{i,j} \\textbf{D}_k[i,j] \\\\\n",
    "            \\text{s.t.}& \\quad \\sum_{j\\in\\mathcal{S}_0^k}z_{i,j} = 1, \\quad \\forall i \\in \\mathcal{S}_1^k \\\\\n",
    "            & \\quad \\sum_{i\\in\\mathcal{S}_1^k}z_{i,j} \\leq 1, \\quad \\forall j \\in \\mathcal{S}_0^k \\\\\n",
    "            &\\quad z_{i,j}\\in\\{0,1\\} \\quad \\forall i \\in\\mathcal{S}_1^k,~j\\in\\mathcal{S}_0^k,\n",
    "        \\end{aligned}$$\n",
    "where ${S}_0^k, {S}_1^k$ is the set of control patients and the set of treatment patients in bucket $k$ respectively. Report the control patients that are matched in the first bucket. You may report them by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdf98e-b92f-4465-a8af-e4cf5947f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "function matching(dist_matrix)\n",
    "    m = Model(Gurobi.Optimizer)\n",
    "    set_optimizer_attribute(m, \"OutputFlag\", 0)\n",
    "\n",
    "    # [TODO]\n",
    "    \n",
    "    optimize!(m);\n",
    "    assignment = value.(z)\n",
    "    return objective_value(m), assignment\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6217672-6393-44ab-918d-4b60549aa6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for i in 1:length(groups)\n",
    "    g_dist = group_dist[i]\n",
    "    obj, assignment = matching(g_dist)\n",
    "    g = groups[i]\n",
    "    control = filter(row -> row.treatment == \"observation\", g)\n",
    "    treatment = filter(row -> row.treatment == \"splenectomy\", g)\n",
    "    \n",
    "    control_matched_idx = [idx[1] for idx in findall(val -> val == 1, assignment)]\n",
    "    control_matched = control[control_matched_idx, :]\n",
    "    push!(data_list, treatment)\n",
    "    push!(data_list, control_matched)\n",
    "\n",
    "    # [TODO: print the control patients that are matched in the first bucket]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31154c-0dcc-48b0-8327-62d73d6f3701",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "We now perform the second main step of R.O.A.D., which aims to remove unobserved confounding. Recall that the first step of R.O.A.D, implemented in Part 2, produces matched pairs of treatment and control patients. We can combine these matched pairs across buckets to get a \"cleaner'\" subset of the full dataset (\"removed\" observed confounding). We will call this the matched dataset. We now train two estimators -- one for the control group and one for the treatment group -- to perform counterfactual estimation, while finetuning a  parameter $\\rho$ to remove the unobserved confounding.\n",
    "\n",
    "We begin by combine the matched pairs across buckets to produce the matched dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52222f6c-a28b-4bea-b96c-f01a916c489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_data = reduce(vcat, data_list)\n",
    "first(matched_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c947cb-e8ab-43a8-bc6b-ebf45c2b73cf",
   "metadata": {},
   "source": [
    "### Part 2(a) - 2.5 points\n",
    "\n",
    "On the control patients in the matched dataset, train a `RandomForest` via `GridSearch` to predict the outcome; use cross-validation to finetune the hyperparameters amongst the same possible values as in Part 1(a). This is training a *__control__* model; we denote the predicted mortality risk from this model for patient $\\boldsymbol{x}_i$ as $h_{t=0}(\\boldsymbol{x}_i)$. \n",
    "     \n",
    "How good is our estimator? That is, what is the AUC and accuracy of our estimator on the control patients in the test set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6caba-d98f-4b98-ae71-08853e0b0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_data_control = filter(row -> row.treatment == \"observation\", matched_data)\n",
    "matched_data_treatment = filter(row -> row.treatment == \"splenectomy\", matched_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa57153-e3df-4ba7-8bd1-c8e27ba079c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train direct estimator for control\n",
    "\n",
    "# grid_rf = [TODO]\n",
    "\n",
    "# IAI.fit_cv!([TODO])\n",
    "\n",
    "# Get best model\n",
    "lnr_control = IAI.get_learner(grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5725394-3a5d-48bd-9874-0d18cfa039ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC, accuracy for test set \n",
    "# println(\"Test AUC score: \", round([TODO], digits=4))\n",
    "# println(\"Test Accuracy: \", round([TODO], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d1228-c816-4abc-9b6d-1106a29c0fe9",
   "metadata": {},
   "source": [
    "### Part 2(b) - 2.5 points\n",
    "\n",
    "Now train a `RandomForest` via `GridSearch` on the treatment patients in the matched dataset to predict the outcome; use cross-validation to finetune the hyperparameters amongst the same possible values as in Part 2(a). This is training a *__treatment__* model; we denote the predicted mortality risk from this model for patient $\\boldsymbol{x}_i$ as $h_{t=1}(\\boldsymbol{x}_i)$. \n",
    "        \n",
    "How good is our estimator? That is, what is the AUC and accuracy of our estimator on the control patients in the test set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97148f1-a9af-4cde-99e6-c3c353f31a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train direct estimator for treatment\n",
    "\n",
    "# grid_rf = IAI.GridSearch([TODO])\n",
    "\n",
    "# IAI.fit_cv!([TODO])\n",
    "\n",
    "# Get best model\n",
    "lnr_treatment = IAI.get_learner(grid_rf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c87dd9-3063-4166-b4f6-76421195c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC, accuracy for test set \n",
    "# println(\"Test AUC score: \", round([TODO], digits=4))\n",
    "# println(\"Test Accuracy: \", round([TODO], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072d3b6-611a-4a6c-8c65-949c7b30f6c7",
   "metadata": {},
   "source": [
    "### Part 2(c) - 3 points\n",
    "\n",
    "Use both the control model and the treatment model to predict the mortality risk on the matched dataset. What do you notice about the outcomes of the control model and the treatment model? In particular, answer this by evaluating and reporting the following quantity on the matched dataset: $$\\hat{w}_{t=1} - \\hat{w}_{t=0},\\quad\\text{where }\\hat{w}_{t=1} = \\frac{1}{n_s}\\sum_{i=1}^{n_s} h_{t=1}(\\boldsymbol{x}_i), ~\\hat{w}_{t=0} = \\frac{1}{n_s}\\sum_{i=1}^{n_s}h_{t=0}(\\boldsymbol{x}_i),$$\n",
    "where $n_s$ is the number of patients in our matched dataset. \n",
    "\n",
    "What does this mean, are there any issues, and what should we do about it, if anything? (Please answer this in a __markdown__ cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d1aa7b-9eda-473f-a3af-1804db173bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_matched = matched_data[:, Not([:treatment, :o_mortality, :y_proba])]\n",
    "\n",
    "# [TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dadd53b-2223-43b1-a2a7-9d421f9424bd",
   "metadata": {},
   "source": [
    "[Space to answer the question]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682003b8-f78a-4130-8024-63aa5b6a8d77",
   "metadata": {},
   "source": [
    "### Part 2(d) - 5 points\n",
    "\n",
    "Implement your suggestion in Part 2(c). \n",
    "\n",
    "*__Hint:__* If your suggestion includes tuning the parameter $\\rho$, then finetune $\\rho$ across the following possible values: [1, 1.5, 2, 2.5]. For each $\\rho$ value, train a corresponding *__treatment__* model, e.g. repeat Part 2(c), *__but in a sample-weighted manner__* such that the surviving (non-expired) patients have weight $\\rho$ and expired patients have weight $1$ (see [documentation](https://docs.interpretable.ai/stable/IAIBase/data/#Sample-Weights)). For each model trained in this manner with the corresponding $\\rho$, evaluate the corresponding quantity $\\hat{w}_{t=1} - \\hat{w}_{t=0}$. Select the $\\rho$ and corresponding treatment model such that this quantity is closest \\textit{in magnitude} to zero. Report your selected $\\rho$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rho = nothing\n",
    "best_diff = nothing\n",
    "best_lnr_treatment = nothing\n",
    "\n",
    "for rho in [1, 1.5, 2, 2.5]\n",
    "    println(\"Running for rho \", rho)\n",
    "    # grid_rf = [TODO]\n",
    "    \n",
    "    # IAI.fit_cv!([TODO])\n",
    "    \n",
    "    # Get best model\n",
    "    lnr_treatment = IAI.get_learner(grid_rf)\n",
    "    \n",
    "    # Display selected model's parameters\n",
    "    # diff = [TODO: w_1 - w_0 quantity]\n",
    "    \n",
    "    if best_rho == nothing || abs(diff) < abs(best_diff)\n",
    "        best_rho = rho\n",
    "        best_diff = diff\n",
    "        best_lnr_treatment = lnr_treatment\n",
    "    end\n",
    "end\n",
    "println(\"******************\")\n",
    "println(\"Best rho \", best_rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a89c843-eb4e-4bb1-aa33-e8d12534ca6e",
   "metadata": {},
   "source": [
    "### Part 2(e) - 4 points\n",
    "\n",
    "We use the learner for the control model and the learner for the treatment model to estimate outcomes for the matched data and organize this into a `DataFrame` where the rows are the individuals and the columns are treatment/no treatment. This will serve as our rewards matrix.\n",
    "\n",
    "Using the matched data and this rewards matrix, train an `Optimal Policy Tree` via `GridSearch` and use cross-validation to finetune the hyperparameters amongst the following possible values: `max_depth` of [4, 5] and `minbucket` of [20, 50]. Provide a screenshot of the tree in your writeup (or make sure it is visible in your code). What is the sensitivity and specificity on the *__test set__*?  Recall the definition of sensitivity and specificity in R.O.A.D.:\n",
    "- Sensitivity = out of the historically-untreated patients that expired, what fraction were prescribed treatment by the model\n",
    "- Specificity = out of the historically-untreated patients that did not expire (survived), what fraction were not prescribed treatment by the model\n",
    "\n",
    "How can we interpret the sensitivity and specificity of our R.O.A.D. model and what is a critical assumption about the treatment that we use when training and evaluating our model? Please answer this question in the provided *__markdown__* cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22dcb45-7285-4747-8f4e-04de7c4ee1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewards matrix\n",
    "\n",
    "rewards_c_matched = IAI.predict_proba(lnr_control, X_matched)[:, 2];\n",
    "rewards_t_matched = IAI.predict_proba(best_lnr_treatment, X_matched)[:, 2]\n",
    "rewards_matched = DataFrame(Dict(\"observation\" => rewards_c_matched, \"splenectomy\" => rewards_t_matched))\n",
    "first(rewards_matched, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f07c58-37fa-4d9e-bb3e-b2cad0d2e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_opt_road = [TODO]\n",
    "\n",
    "# IAI.fit_cv!([TODO])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0757ac10-e5ff-483a-bff3-a69cdf13e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "IAI.show_in_browser(grid_opt_road)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f359733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity = [TODO]\n",
    "# specificity = [TODO]\n",
    "\n",
    "# println(\"Sensitivity: \", sensitivity)\n",
    "# println(\"Specificity: \", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc917ae-b1d4-428d-a7a3-8b833f708010",
   "metadata": {},
   "source": [
    "[Space to answer the question]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d0cfe-2955-48c5-a3ea-5832425ac536",
   "metadata": {},
   "source": [
    "### Part 2(f) - 4 points\n",
    "\n",
    "We will now compare the R.O.A.D. model with an OPT trained on the unadulterated training data. Using the *__original__* data, train a *__doubly-robust__* reward estimator (see [documentation](https://docs.interpretable.ai/stable/OptimalTrees/quickstart/policy_categorical/)) on the training set to get a rewards matrix. Use the original data and this new rewards matrix to train an `Optimal Policy Tree` via `GridSearch` and use cross-validation to finetune the hyperparameters amongst the same possible values as 3(e). Provide a screenshot of the tree in your writeup (or make sure it is visible in your code). What is the sensitivity and specificity?\n",
    "\n",
    "How doees this tree differ from the tree trained via the R.O.A.D. methodology? How does the sensitivity/specificity differ? What does this mean? Please be concise in your answer (<=5 sentences) and use the provided *__markdown__* space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1f574-1199-4978-8935-9548028c169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward_lnr = [TODO]\n",
    "# train_pred, train_reward_score = IAI.fit_predict!([TODO])\n",
    "# rewards_train = train_pred[:reward];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb71b71-400a-488b-9b6e-823fdb6edc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_opt_regular = [TODO]\n",
    "# IAI.fit_cv!([TODO])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c49e84-dcf0-43a1-86b8-bebf804ef83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IAI.show_in_browser(grid_opt_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f59536-99e8-478a-b1b4-a063d2d4ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity = [TODO]\n",
    "# specificity = [TODO]\n",
    "\n",
    "# println(sensitivity)\n",
    "# println(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8abd9-f1f5-4226-87e0-b04119aa73b5",
   "metadata": {},
   "source": [
    "[Space to answer the question]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
